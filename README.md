# Letrus Plagiarism Service

Servi√ßo de compara√ß√£o/similaridade textual para detec√ß√£o de pl√°gio, com tr√™s estrat√©gias:

- **L√©xico (TF‚ÄëIDF)**: An√°lise baseada em frequ√™ncia de termos, r√°pida e eficiente para detec√ß√£o de c√≥pia direta
- **Sem√¢ntico (embeddings densos)**: Compreens√£o sem√¢ntica via Sentence Transformers, captura similaridade conceitual
- **H√≠brido (fus√£o RRF)**: Combina o melhor dos dois mundos - precis√£o sem√¢ntica + robustez lexical

A API √© constru√≠da com FastAPI e exposta em `/docs`.

## Sum√°rio
- [Arquitetura](#arquitetura)
- [Requisitos](#requisitos)
- [Execu√ß√£o com Docker Compose (recomendado)](#execu√ß√£o-com-docker-compose-recomendado)
- [Execu√ß√£o local (sem Docker)](#execu√ß√£o-local-sem-docker)
- [Uso da API](#uso-da-api)
- [Testes](#testes)
- [Configura√ß√£o](#configura√ß√£o)
- [Estrutura do projeto](#estrutura-do-projeto)
- [Solu√ß√£o de problemas](#solu√ß√£o-de-problemas)


## Arquitetura
- `FastAPI` exp√µe os endpoints (`/health`, `/compare`).
- Camada de servi√ßo (`CompareService`) orquestra:
  - **L√©xico**: TF‚ÄëIDF local com `scikit-learn` - r√°pido e eficiente para detec√ß√£o de c√≥pia direta
  - **Sem√¢ntico**: Qdrant como vetor DB com embeddings densos via Sentence Transformers
  - **H√≠brido**: Fus√£o RRF (Reciprocal Rank Fusion) entre denso e esparso (BM25) - combina precis√£o sem√¢ntica com robustez lexical
- `scripts/indexer.py` cria/garante cole√ß√µes no Qdrant e indexa o corpus.
- `scripts/download_data.py` baixa um subconjunto do Wikipedia PT e salva em `data/raw`.

### Por que a estrat√©gia h√≠brida?

A estrat√©gia h√≠brida combina as vantagens de ambas as abordagens:
- **L√©xico (TF-IDF)**: Excelente para detectar c√≥pias diretas, par√°frases e reordena√ß√µes de frases
- **Sem√¢ntico (embeddings)**: Captura similaridade conceitual mesmo quando as palavras s√£o diferentes
- **Fus√£o RRF**: Combina os rankings de ambas as estrat√©gias de forma inteligente, priorizando documentos que aparecem bem posicionados em ambas as listas

Esta abordagem √© especialmente eficaz para detec√ß√£o de pl√°gio em portugu√™s, onde varia√ß√µes lingu√≠sticas e sin√¥nimos s√£o comuns.


## Requisitos
- Python 3.12+
- Docker e Docker Compose (para sem√¢ntico/h√≠brido e execu√ß√£o completa)


## Execu√ß√£o com Docker Compose (recomendado)
Este √© o caminho mais simples para subir tudo (Qdrant + indexa√ß√£o + API).

**‚ö†Ô∏è Importante**: Na primeira execu√ß√£o, o servi√ßo pode demorar alguns minutos para subir devido ao download dos modelos de linguagem (Sentence Transformers). Este √© um processo √∫nico - nas pr√≥ximas execu√ß√µes ser√° muito mais r√°pido.

**üìÅ Pr√©-requisito**: Certifique-se de que o arquivo `data/raw/wikipedia-PT-300.jsonl` existe no projeto. Este arquivo cont√©m o corpus que ser√° indexado no Qdrant.

1) Subir os servi√ßos:
   ```bash
   docker compose up --build
   ```

   O fluxo ser√°:
   - `qdrant` sobe e fica dispon√≠vel em `localhost:6333`.
   - `indexer` espera o `qdrant` estar saud√°vel e indexa o corpus nas cole√ß√µes configuradas.
   - `api` inicia ap√≥s o `indexer` concluir com sucesso, expondo a API em `http://localhost:8000`.

   **‚è±Ô∏è Tempo de inicializa√ß√£o**: Na primeira execu√ß√£o, pode levar demorar devido ao download dos modelos de linguagem. Nas pr√≥ximas execu√ß√µes ser√° muito mais r√°pido.

2) Acesse a documenta√ß√£o interativa em:
   - `http://localhost:8000/docs`
   - `http://localhost:8000/redoc`


## Execu√ß√£o local (sem Docker)
Voc√™ pode rodar a API localmente para testar o modo l√©xico (TF‚ÄëIDF) sem Qdrant. Para sem√¢ntico/h√≠brido, prefira o Docker Compose.

**‚ö†Ô∏è Nota**: Para usar estrat√©gias sem√¢nticas/h√≠bridas localmente, voc√™ precisar√° ajustar a configura√ß√£o do Qdrant para `localhost:6333` em vez de `http://qdrant:6333`.

**üìÅ Pr√©-requisito**: Certifique-se de que o arquivo `data/raw/wikipedia-PT-300.jsonl` existe no projeto.

1) Ambiente e depend√™ncias:
```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

2) Rodar a API (aten√ß√£o: sem Qdrant, use `mode=lexical` nos requests):
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```


## Uso da API
### Healthcheck
```bash
curl -s http://localhost:8000/health
```

### Compara√ß√£o (POST /compare)
Body:
```json
{
  "text": "Seu trecho aqui",
  "top_k": 5,
  "mode": "all" // "lexical" | "semantic" | "hybrid" | "all"
}
```

Exemplos:
- L√©xico (n√£o requer Qdrant):
  ```bash
  curl -s -X POST http://localhost:8000/compare \
    -H 'Content-Type: application/json' \
    -d '{"text": "A linguagem Python √©...", "top_k": 5, "mode": "lexical"}' | jq
  ```

- Sem√¢ntico (requer Qdrant ativo e corpus indexado):
  ```bash
  curl -s -X POST http://localhost:8000/compare \
    -H 'Content-Type: application/json' \
    -d '{"text": "A linguagem Python √©...", "top_k": 5, "mode": "semantic"}' | jq
  ```

- H√≠brido (requer Qdrant):
  ```bash
  curl -s -X POST http://localhost:8000/compare \
    -H 'Content-Type: application/json' \
    -d '{"text": "A linguagem Python √©...", "top_k": 5, "mode": "hybrid"}' | jq
  ```

- Todas as estrat√©gias (requer Qdrant):
  ```bash
  curl -s -X POST http://localhost:8000/compare \
    -H 'Content-Type: application/json' \
    -d '{"text": "A linguagem Python √©...", "top_k": 5, "mode": "all"}' | jq
  ```

Respostas seguem o schema:
```json
{
  "mode": "all",
  "lexical": [{"index": 123, "score": 0.78, "text": "..."}],
  "semantic": [{"id": "...", "score": 0.82, "text": "..."}],
  "hybrid": [{"id": "...", "score": 0.86, "text": "..."}]
}
```


## Testes
Rodar localmente:
```bash
pytest -q
```

Observa√ß√µes:
- Para que os testes que exercitam o endpoint `/compare` passem em modo padr√£o (`mode=all`), √© necess√°rio que:
  1) O dataset exista em `data/raw/wikipedia-PT-300.jsonl` (rode `python -m scripts.download_data`).
  2) O Qdrant esteja rodando e as cole√ß√µes estejam indexadas (use `docker compose up` antes de executar os testes).


## Configura√ß√£o
As configura√ß√µes padr√£o est√£o em `app/config/config.py`:

- `qdrant_url`: URL do Qdrant 
  - **Docker Compose**: `http://qdrant:6333` (padr√£o)
  - **Execu√ß√£o local**: `http://localhost:6333` (ajuste necess√°rio)
- `model_dense_name`: Modelo de embeddings densos (Sentence Transformers).
- `model_sparse_name`: Modelo esparso (BM25 via Qdrant).
- `dense_name` / `sparse_name`: nomes dos espa√ßos vetoriais nas cole√ß√µes.
- `qdrant_collection_hybrid` / `qdrant_collection_dense`: nomes das cole√ß√µes.
- `data_path`: caminho do JSONL com o corpus (padr√£o: `data/raw/wikipedia-PT-300.jsonl`).

**‚ö†Ô∏è Para execu√ß√£o local**: Se voc√™ quiser usar estrat√©gias sem√¢nticas/h√≠bridas sem Docker, altere `qdrant_url` para `http://localhost:6333` no arquivo de configura√ß√£o.

Sugest√£o futura: externalizar essas configura√ß√µes via vari√°veis de ambiente.


## Estrutura do projeto
```
app/
  ai/
    lexical/tfidf.py           # Similaridade TF‚ÄëIDF
    semantic/indexer.py        # Cria√ß√£o/garantia de cole√ß√µes e upsert no Qdrant
    semantic/retriever.py      # Buscas dense-only e h√≠bridas (RRF)
  api/compare.py               # Rotas FastAPI
  services/compare_service.py  # Orquestra l√©xico/sem√¢ntico
  schema/compare.py            # Pydantic models
  utils/json_utils.py          # Leitura de JSONL
  main.py                      # Cria√ß√£o do app FastAPI

scripts/
  download_data.py             # Baixa Wikipedia PT (amostras)
  indexer.py                   # Indexa no Qdrant

docker-compose.yml             # Orquestra qdrant + indexer + api
Dockerfile                     # Imagem da API
tests/                         # Testes b√°sicos de rota
```


## Solu√ß√£o de problemas
- Erro: `Nenhum texto encontrado em data/raw/wikipedia-PT-300.jsonl`
  - Certifique-se de que o arquivo `data/raw/wikipedia-PT-300.jsonl` existe no projeto.

- Erro de conex√£o com Qdrant ao usar `semantic`/`hybrid`/`all`:
  - Garanta que o Qdrant est√° rodando (no Compose, ele sobe automaticamente) e que as cole√ß√µes foram criadas/indexadas pelo `indexer`.
  - **Para execu√ß√£o local**: Verifique se a URL do Qdrant est√° configurada como `http://localhost:6333`.

- **Modelos levam muito tempo para baixar na primeira execu√ß√£o**:
  - √â esperado para o `SentenceTransformer` (pode levar 3-5 minutos na primeira vez).
  - O cache √© reutilizado nas pr√≥ximas execu√ß√µes do container/host.
  - Este √© um processo √∫nico - nas pr√≥ximas execu√ß√µes ser√° muito mais r√°pido.

- Execu√ß√£o local sem Docker n√£o encontra Qdrant:
  - Prefira usar `mode=lexical` ou suba tudo via Docker Compose.
  - **Alternativa**: Se voc√™ tiver Qdrant rodando localmente, ajuste a configura√ß√£o para `http://localhost:6333`.

- **Servi√ßo demora para subir**:
  - Na primeira execu√ß√£o, √© normal demorar alguns minutos devido ao download dos modelos.
  - Verifique os logs do container para acompanhar o progresso.
  - Nas pr√≥ximas execu√ß√µes ser√° muito mais r√°pido.


---
Feito para o desafio t√©cnico. Qualquer d√∫vida, verifique `/docs` e os arquivos em `app/` e `scripts/`.